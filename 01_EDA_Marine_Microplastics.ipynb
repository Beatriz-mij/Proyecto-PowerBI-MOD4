{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db10fb50",
   "metadata": {},
   "source": [
    "# EDA Marine Microplastics 🌊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a654f",
   "metadata": {},
   "source": [
    "## Importación de librerías y datos 📁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imputación de nulos usando métodos avanzados estadísticos\n",
    "# -----------------------------------------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30041278",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Archivos/Marine_Microplastics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_mp \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../Archivos/Marine_Microplastics.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_mp\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\isaw9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isaw9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\isaw9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\isaw9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\isaw9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Archivos/Marine_Microplastics.csv'"
     ]
    }
   ],
   "source": [
    "df_mp = pd.read_csv(\"../../Archivos/Marine_Microplastics.csv\")\n",
    "df_mp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f4155f",
   "metadata": {},
   "source": [
    "### Primera exploración 🔎"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26221a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33114a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>Oceans</th>\n",
       "      <th>Regions</th>\n",
       "      <th>SubRegions</th>\n",
       "      <th>Sampling Method</th>\n",
       "      <th>Measurement</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Density Range</th>\n",
       "      <th>Density Class</th>\n",
       "      <th>Short Reference</th>\n",
       "      <th>Long Reference</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Accession Number</th>\n",
       "      <th>Accession Link</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Date</th>\n",
       "      <th>GlobalID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9198</th>\n",
       "      <td>19864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hand picking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieces/10 mins</td>\n",
       "      <td>40-200</td>\n",
       "      <td>High</td>\n",
       "      <td>Tunnell et al. 2020</td>\n",
       "      <td>Tunnell, Jace W.; Dunning, Kelly H.; Scheef, L...</td>\n",
       "      <td>https://doi.org/10.1016/j.marpolbul.2019.110794</td>\n",
       "      <td>University of Texas Marine Science Institute</td>\n",
       "      <td>Nurdle Patrol</td>\n",
       "      <td>259486</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/metadata/land...</td>\n",
       "      <td>43.0544</td>\n",
       "      <td>-78.9004</td>\n",
       "      <td>8/8/2021 12:00:00 AM</td>\n",
       "      <td>2219b0dc-6699-4acf-aaa9-bbb338cb85e4</td>\n",
       "      <td>-78.9004</td>\n",
       "      <td>43.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>16266</td>\n",
       "      <td>Atlantic Ocean</td>\n",
       "      <td>Gulf of Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hand picking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieces/10 mins</td>\n",
       "      <td>2-40</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tunnell et al. 2020</td>\n",
       "      <td>Tunnell, Jace W.; Dunning, Kelly H.; Scheef, L...</td>\n",
       "      <td>https://doi.org/10.1016/j.marpolbul.2019.110794</td>\n",
       "      <td>University of Texas Marine Science Institute</td>\n",
       "      <td>Nurdle Patrol</td>\n",
       "      <td>259486</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/metadata/land...</td>\n",
       "      <td>30.3062</td>\n",
       "      <td>-89.3276</td>\n",
       "      <td>5/3/2019 12:00:00 AM</td>\n",
       "      <td>134b6a0d-b979-4ccf-9bac-88a30c5da7a0</td>\n",
       "      <td>-89.3276</td>\n",
       "      <td>30.3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>6874</td>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neuston net</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>pieces/m3</td>\n",
       "      <td>0-0.0005</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>Law et al.2014</td>\n",
       "      <td>Law, K.L, S.K. Morét-Ferguson, D.S. Goodwin, E...</td>\n",
       "      <td>https://doi.org/10.1021/es4053076</td>\n",
       "      <td>Sea Education Association</td>\n",
       "      <td>SEA</td>\n",
       "      <td>211008</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/metadata/land...</td>\n",
       "      <td>23.6500</td>\n",
       "      <td>-149.7400</td>\n",
       "      <td>2/16/2005 12:00:00 AM</td>\n",
       "      <td>97d8e70c-313a-4052-a77f-6bc82573552c</td>\n",
       "      <td>-149.7400</td>\n",
       "      <td>23.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16250</th>\n",
       "      <td>11699</td>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neuston net</td>\n",
       "      <td>5.67537</td>\n",
       "      <td>pieces/m3</td>\n",
       "      <td>1-10</td>\n",
       "      <td>High</td>\n",
       "      <td>Eriksen et al.2014</td>\n",
       "      <td>Eriksen, M., L.C.M. Lebreton, H.S. Carson, M. ...</td>\n",
       "      <td>https://doi.org/10.1371/journal.pone.0111913</td>\n",
       "      <td>5 Gyres Institute</td>\n",
       "      <td>SV Mir; ORV Alguita; SV Sea Dragon; RV Stad Am...</td>\n",
       "      <td>275968</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/metadata/land...</td>\n",
       "      <td>36.0135</td>\n",
       "      <td>-140.1468</td>\n",
       "      <td>9/27/2009 12:00:00 AM</td>\n",
       "      <td>8f47431b-ac05-4190-82f6-8f1977e4247d</td>\n",
       "      <td>-140.1468</td>\n",
       "      <td>36.0135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10148</th>\n",
       "      <td>6345</td>\n",
       "      <td>Pacific Ocean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neuston net</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>pieces/m3</td>\n",
       "      <td>0-0.0005</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>Law et al.2014</td>\n",
       "      <td>Law, K.L, S.K. Morét-Ferguson, D.S. Goodwin, E...</td>\n",
       "      <td>https://doi.org/10.1021/es4053076</td>\n",
       "      <td>Sea Education Association</td>\n",
       "      <td>SEA</td>\n",
       "      <td>211008</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/metadata/land...</td>\n",
       "      <td>53.0700</td>\n",
       "      <td>-133.6600</td>\n",
       "      <td>7/6/2002 12:00:00 AM</td>\n",
       "      <td>adb83574-34d8-45bd-8d4f-4fa3bf3dff02</td>\n",
       "      <td>-133.6600</td>\n",
       "      <td>53.0700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OBJECTID          Oceans         Regions SubRegions Sampling Method  \\\n",
       "9198      19864             NaN             NaN        NaN    Hand picking   \n",
       "5518      16266  Atlantic Ocean  Gulf of Mexico        NaN    Hand picking   \n",
       "552        6874   Pacific Ocean             NaN        NaN     Neuston net   \n",
       "16250     11699   Pacific Ocean             NaN        NaN     Neuston net   \n",
       "10148      6345   Pacific Ocean             NaN        NaN     Neuston net   \n",
       "\n",
       "       Measurement            Unit Density Range Density Class  \\\n",
       "9198           NaN  pieces/10 mins        40-200          High   \n",
       "5518           NaN  pieces/10 mins          2-40        Medium   \n",
       "552        0.00000       pieces/m3      0-0.0005      Very Low   \n",
       "16250      5.67537       pieces/m3          1-10          High   \n",
       "10148      0.00000       pieces/m3      0-0.0005      Very Low   \n",
       "\n",
       "           Short Reference                                     Long Reference  \\\n",
       "9198   Tunnell et al. 2020  Tunnell, Jace W.; Dunning, Kelly H.; Scheef, L...   \n",
       "5518   Tunnell et al. 2020  Tunnell, Jace W.; Dunning, Kelly H.; Scheef, L...   \n",
       "552         Law et al.2014  Law, K.L, S.K. Morét-Ferguson, D.S. Goodwin, E...   \n",
       "16250   Eriksen et al.2014  Eriksen, M., L.C.M. Lebreton, H.S. Carson, M. ...   \n",
       "10148       Law et al.2014  Law, K.L, S.K. Morét-Ferguson, D.S. Goodwin, E...   \n",
       "\n",
       "                                                   DOI  \\\n",
       "9198   https://doi.org/10.1016/j.marpolbul.2019.110794   \n",
       "5518   https://doi.org/10.1016/j.marpolbul.2019.110794   \n",
       "552                  https://doi.org/10.1021/es4053076   \n",
       "16250     https://doi.org/10.1371/journal.pone.0111913   \n",
       "10148                https://doi.org/10.1021/es4053076   \n",
       "\n",
       "                                       Organization  \\\n",
       "9198   University of Texas Marine Science Institute   \n",
       "5518   University of Texas Marine Science Institute   \n",
       "552                       Sea Education Association   \n",
       "16250                             5 Gyres Institute   \n",
       "10148                     Sea Education Association   \n",
       "\n",
       "                                                Keywords  Accession Number  \\\n",
       "9198                                       Nurdle Patrol            259486   \n",
       "5518                                       Nurdle Patrol            259486   \n",
       "552                                                  SEA            211008   \n",
       "16250  SV Mir; ORV Alguita; SV Sea Dragon; RV Stad Am...            275968   \n",
       "10148                                                SEA            211008   \n",
       "\n",
       "                                          Accession Link  Latitude  Longitude  \\\n",
       "9198   https://www.ncei.noaa.gov/access/metadata/land...   43.0544   -78.9004   \n",
       "5518   https://www.ncei.noaa.gov/access/metadata/land...   30.3062   -89.3276   \n",
       "552    https://www.ncei.noaa.gov/access/metadata/land...   23.6500  -149.7400   \n",
       "16250  https://www.ncei.noaa.gov/access/metadata/land...   36.0135  -140.1468   \n",
       "10148  https://www.ncei.noaa.gov/access/metadata/land...   53.0700  -133.6600   \n",
       "\n",
       "                        Date                              GlobalID         x  \\\n",
       "9198    8/8/2021 12:00:00 AM  2219b0dc-6699-4acf-aaa9-bbb338cb85e4  -78.9004   \n",
       "5518    5/3/2019 12:00:00 AM  134b6a0d-b979-4ccf-9bac-88a30c5da7a0  -89.3276   \n",
       "552    2/16/2005 12:00:00 AM  97d8e70c-313a-4052-a77f-6bc82573552c -149.7400   \n",
       "16250  9/27/2009 12:00:00 AM  8f47431b-ac05-4190-82f6-8f1977e4247d -140.1468   \n",
       "10148   7/6/2002 12:00:00 AM  adb83574-34d8-45bd-8d4f-4fa3bf3dff02 -133.6600   \n",
       "\n",
       "             y  \n",
       "9198   43.0544  \n",
       "5518   30.3062  \n",
       "552    23.6500  \n",
       "16250  36.0135  \n",
       "10148  53.0700  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6e099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ===================== Informe de Datos =====================\n",
      "    \n",
      "    Porcentaje de Nulos por Columna:\n",
      "    ------------------------------------------------------------\n",
      "    OBJECTID             0.000000\n",
      "Oceans               0.000000\n",
      "Regions              0.000000\n",
      "SubRegions          93.600979\n",
      "Sampling Method      0.000000\n",
      "Measurement         28.455324\n",
      "Unit                 0.000000\n",
      "Density Range        0.000000\n",
      "Density Class        0.000000\n",
      "Short Reference      0.000000\n",
      "Long Reference       0.000000\n",
      "DOI                  0.000000\n",
      "Organization         0.000000\n",
      "Keywords             0.088127\n",
      "Accession Number     0.000000\n",
      "Accession Link       0.000000\n",
      "Latitude             0.000000\n",
      "Longitude            0.000000\n",
      "Date                 0.000000\n",
      "GlobalID             0.000000\n",
      "x                    0.000000\n",
      "y                    0.000000\n",
      "    \n",
      "    ------------------------------------------------------------\n",
      "    Duplicados:\n",
      "    ------------------------------------------------------------\n",
      "    No hay duplicados\n",
      "    \n",
      "    ============================================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Función para conocer nulos y duplicados en un informe. Next step--> ETL\n",
    "\n",
    "def nulos_duplicados(df_mp):\n",
    "    # Cálculo del porcentaje de nulos\n",
    "    porcentaje_nulos = df_mp.isna().sum() / df_mp.shape[0] * 100\n",
    "    \n",
    "    # Verificación de duplicados\n",
    "    duplicados = df_mp.duplicated().sum()\n",
    "    if duplicados == 0:\n",
    "        mensaje_duplicados = \"No hay duplicados\"\n",
    "    else:\n",
    "        mensaje_duplicados = f\"Hay {duplicados} duplicados\"\n",
    "    \n",
    "    # Creación de un reporte bonito y visual\n",
    "    reporte = f\"\"\"\n",
    "    ===================== Informe de Datos =====================\n",
    "    \n",
    "    Porcentaje de Nulos por Columna:\n",
    "    ------------------------------------------------------------\n",
    "    {porcentaje_nulos.to_string()}\n",
    "    \n",
    "    ------------------------------------------------------------\n",
    "    Duplicados:\n",
    "    ------------------------------------------------------------\n",
    "    {mensaje_duplicados}\n",
    "    \n",
    "    ============================================================\n",
    "    \"\"\"\n",
    "    \n",
    "    # Imprimir directamente el reporte\n",
    "    print(reporte)\n",
    "\n",
    "# Ejemplo de uso\n",
    "# df_mp = pd.DataFrame(...)\n",
    "\n",
    "# Llamar directamente a la función\n",
    "nulos_duplicados(df_mp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c99b4e",
   "metadata": {},
   "source": [
    "### Gestión de duplicados y nulos ✏️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestión de duplicados: No procede. No hay duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestión de nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobación de nulos para la columna 'Oceans' de un dataframe:\n",
    "print(f\"Número de puntos con 'Oceans' nulo: {df_mp['Oceans'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conocer las columnas de mi capa .shp que suaremos en shapely\n",
    "print(ocean_shapes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6838ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Primero, seleccionamos los puntos que son nulos, en nuestra columna \"Oceans\"\n",
    "df_nulos = df_mp[df_mp['Oceans'].isna()].copy()\n",
    "\n",
    "# Creamos una geometría, con ayuda de nuestras columnas Lon y Lat (donde no hay nulos)\n",
    "df_nulos['geometry'] = df_nulos.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
    "\n",
    "# Creamos el \"GeoDataFrame\" para puntos nulos\n",
    "gdf_nulos = gpd.GeoDataFrame(df_nulos, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Cargamos un archivo shapefile, una capa con información sobre los oceanos\n",
    "# Este shapefle tiene esta info:\n",
    "#'name', 'latitude', 'longitude', 'min_Y', 'min_X', 'max_Y', 'max_X','area_km2', 'geometry'\n",
    "ocean_shapes = gpd.read_file(\"../../Archivos/goas_v01.shp\")\n",
    "\n",
    "# Realizamos la unión espacial más cercana con sjoin.nearest:\n",
    "gdf_nulos_nearest = gpd.sjoin_nearest(gdf_nulos, ocean_shapes, how='left', distance_col='dist')\n",
    "\n",
    "# Asignamos el nombre correcto de los océanos a la columna 'Oceans' que tiene relación con la unión.\n",
    "gdf_nulos_nearest['Oceans'] = gdf_nulos_nearest['name']  \n",
    "\n",
    "# Ahora actualizamos el DataFrame original 'df' con los valores de 'Oceans'\n",
    "df_mp.loc[gdf_nulos_nearest.index, 'Oceans'] = gdf_nulos_nearest['Oceans']\n",
    "\n",
    "# Volvemos a comprobar los puntos con oceano nulo, en 'Oceans:\n",
    "print(f\"Número de puntos con 'Oceans' nulo: {df_mp['Oceans'].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b30284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conocer las columnas de mi capa .shp\n",
    "print(ocean_shapes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobación de que la herramienta de geopandas, ha funcionado. Este océano ha sido \"generado\"\n",
    "df_mp[df_mp['OBJECTID'] == 19864]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df01993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos los valores únicos para 'Oceans'\n",
    "df_mp['Oceans'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6870187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo tienen mayor detalle geográfico del esperado, convertimos el resultado para obtener una región más amplia y acorde a los datos\n",
    "df_mp=df_mp.replace(\"North Atlantic Ocean\", \"Atlantic Ocean\")\n",
    "df_mp=df_mp.replace(\"North Pacific Ocean\",\"Pacific Ocean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volvemos a comprobar los valores únicos para 'Oceans'\n",
    "df_mp['Oceans'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ababe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACEMOS LO MISMO PARA REGIONES:\n",
    "\n",
    "# Seleccionar solo los puntos nulos en 'Oceans'\n",
    "df_nulos = df_mp[df_mp['Regions'].isna()].copy()\n",
    "\n",
    "# Crear geometría a partir de latitud y longitud\n",
    "df_nulos['geometry'] = df_nulos.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
    "\n",
    "# Crear el GeoDataFrame para puntos nulos\n",
    "gdf_nulos = gpd.GeoDataFrame(df_nulos, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "# Cargar el shapefile con las formas de los océanos\n",
    "ocean_shapes = gpd.read_file(\"../../Archivos/goas_v01.shp\")\n",
    "\n",
    "# Realizar la unión espacial más cercana (nearest)\n",
    "gdf_nulos_nearest = gpd.sjoin_nearest(gdf_nulos, ocean_shapes, how='left', distance_col='dist')\n",
    "\n",
    "# Asignar el nombre correcto de los océanos a la columna 'Oceans'\n",
    "gdf_nulos_nearest['Regions'] = gdf_nulos_nearest['name']  # o el nombre correcto de la columna en ocean_shapes\n",
    "\n",
    "# Ahora actualizamos el DataFrame original 'df' con los valores de 'Oceans'\n",
    "df_mp.loc[gdf_nulos_nearest.index, 'Regions'] = gdf_nulos_nearest['Regions']\n",
    "\n",
    "# Imprimir el número de valores nulos en la columna 'Oceans'\n",
    "print(f\"Número de puntos con océano nulo: {df_mp['Regions'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0860d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pieces/m3', 'pieces kg-1 d.w.', 'pieces/10 mins'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobaciones varias:\n",
    "df_mp[\"Unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e1421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unit</th>\n",
       "      <th>pieces kg-1 d.w.</th>\n",
       "      <th>pieces/10 mins</th>\n",
       "      <th>pieces/m3</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sampling Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AVANI net</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aluminum bucket</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTD rosette sampler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day grab</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grab sample</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1181</td>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hand picking</th>\n",
       "      <td>0</td>\n",
       "      <td>5812</td>\n",
       "      <td>18</td>\n",
       "      <td>5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intake seawater pump</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manta net</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2342</td>\n",
       "      <td>2342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Megacorer</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metal spoon</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neuston net</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9830</td>\n",
       "      <td>9830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PVC cylinder</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Petite Ponar benthic grab</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plankton net</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Remotely operated vehicle</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shipek grab sampler</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stainless steel spoon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Van Dorn sampler</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Van Veen grab sampler</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>275</td>\n",
       "      <td>5812</td>\n",
       "      <td>14338</td>\n",
       "      <td>20425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unit                       pieces kg-1 d.w.  pieces/10 mins  pieces/m3    All\n",
       "Sampling Method                                                              \n",
       "AVANI net                                 0               0         18     18\n",
       "Aluminum bucket                           0               0         57     57\n",
       "CTD rosette sampler                       0               0         36     36\n",
       "Day grab                                 17               0          0     17\n",
       "Grab sample                               0               0       1181   1181\n",
       "Hand picking                              0            5812         18   5830\n",
       "Intake seawater pump                      0               0        181    181\n",
       "Manta net                                 0               0       2342   2342\n",
       "Megacorer                                90               0          0     90\n",
       "Metal spoon                              76               0          0     76\n",
       "Neuston net                               0               0       9830   9830\n",
       "PVC cylinder                              0               0        370    370\n",
       "Petite Ponar benthic grab                36               0          0     36\n",
       "Plankton net                              0               0         74     74\n",
       "Remotely operated vehicle                40               0          0     40\n",
       "Shipek grab sampler                       9               0          0      9\n",
       "Stainless steel spoon                     0               0         50     50\n",
       "Van Dorn sampler                          0               0        181    181\n",
       "Van Veen grab sampler                     7               0          0      7\n",
       "All                                     275            5812      14338  20425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comprobaciones varias:\n",
    "# saber a que método corresponden las medidas\n",
    "# Tabla de contingencia entre Métodos y Unidades de Medida\n",
    "contingencia = pd.crosstab(df_mp['Sampling Method'], df_mp['Unit'], margins=True)\n",
    "display(contingencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf00d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede observar, que excepto \"hand picking\" las demás tienen una unidad definida.\n",
    "\n",
    "#Como tenemos nulos en measurement, no en unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sampling Method\n",
       "AVANI net                       0\n",
       "Aluminum bucket                 0\n",
       "CTD rosette sampler             0\n",
       "Day grab                        0\n",
       "Grab sample                     0\n",
       "Hand picking                 5812\n",
       "Intake seawater pump            0\n",
       "Manta net                       0\n",
       "Megacorer                       0\n",
       "Metal spoon                     0\n",
       "Neuston net                     0\n",
       "PVC cylinder                    0\n",
       "Petite Ponar benthic grab       0\n",
       "Plankton net                    0\n",
       "Remotely operated vehicle       0\n",
       "Shipek grab sampler             0\n",
       "Stainless steel spoon           0\n",
       "Van Dorn sampler                0\n",
       "Van Veen grab sampler           0\n",
       "Name: Measurement, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobaciones varias:\n",
    "\n",
    "df_mp.groupby(\"Sampling Method\")[\"Measurement\"].apply(lambda x: x.isnull().sum())\n",
    "# Podemos ver que todos los nulos son de Hand picking, \"recogido a mano\"--> No relevante --> No imputación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a681e",
   "metadata": {},
   "source": [
    "### Transformaciones 💻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40820f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En la columna Density range, tengo un rango. Quedarme con el valor central, para próximos cálculos. Pero sin eliminar la columna original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed08939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.005-1', '0-0.0005', '>=10', '0.0005-0.005', '1-10', '0-2', '0',\n",
       "       '2-40', '40-200', '500-30000', '0-100', '1-2', '2-20', '>200',\n",
       "       '20-150', '>40000', '150-200', '30000-40000'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp[\"Density Range\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38483b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para eliminar el símbolo '>= y >'\n",
    "def eliminar_menor_igual(rango):\n",
    "    return rango.replace('>=','').replace('>','').strip()\n",
    "\n",
    "# Aplicamos la función para eliminar '>=' de la columna 'Density Range'\n",
    "df_mp['Density Range'] = df_mp['Density Range'].apply(eliminar_menor_igual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83e8dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.005-1', '0-0.0005', '10', '0.0005-0.005', '1-10', '0-2', '0',\n",
       "       '2-40', '40-200', '500-30000', '0-100', '1-2', '2-20', '200',\n",
       "       '20-150', '40000', '150-200', '30000-40000'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mp[\"Density Range\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733848ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer los valores numéricos y calcular el valor central\n",
    "def calcular_densidad_central(rango):\n",
    "    # Si el valor es solo un número\n",
    "    if '-' not in rango:  # Caso cuando no hay guion, es un solo número\n",
    "        return float(rango.strip())\n",
    "    \n",
    "    # Si el valor es un rango (con '-')\n",
    "    else:\n",
    "        # Extraemos los valores del rango y calculamos el promedio\n",
    "        min_val, max_val = map(float, rango.replace(' ', '').split('-'))  # Convertimos los valores en float\n",
    "        return (min_val + max_val) / 2  # Calculamos el promedio del rango\n",
    "\n",
    "# Aplicamos la función a la columna 'Density Range' y creamos la nueva columna 'Density_Center'\n",
    "df_mp['Density_Center'] = df_mp['Density Range'].apply(calcular_densidad_central)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oceans\n",
      "Arctic Ocean      [nan, norwegian sea, northwestern passages, be...\n",
      "Atlantic Ocean    [nan, caribbean sea, mediterranean sea, north ...\n",
      "Indian Ocean                     [nan, mozambique channel, red sea]\n",
      "Pacific Ocean     [nan, gulf of california, coastal waters of so...\n",
      "Name: Regions, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Comprobaciones: Agrupar por 'Oceans' y obtener las regiones únicas para cada océano\n",
    "oceans_regions = df_mp.groupby('Oceans')['Regions'].unique()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(oceans_regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Most Frequent Region  Frequency  Percentage\n",
      "Oceans                                                                    \n",
      "Arctic Ocean          (Arctic Ocean, greenland sea)         35   19.662921\n",
      "Atlantic Ocean     (Atlantic Ocean, gulf of mexico)       4817   31.083436\n",
      "Indian Ocean     (Indian Ocean, mozambique channel)          3   15.000000\n",
      "Pacific Ocean   (Pacific Ocean, gulf of california)        116    2.452431\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por 'Oceans' y contar las ocurrencias de cada 'Regions'\n",
    "oceans_regions_count = df_mp.groupby('Oceans')['Regions'].value_counts()\n",
    "\n",
    "# Encontrar la región más frecuente en cada océano\n",
    "most_frequent_region = oceans_regions_count.groupby('Oceans').idxmax()\n",
    "\n",
    "# Contar la frecuencia de la región más frecuente\n",
    "most_frequent_count = oceans_regions_count.groupby('Oceans').max()\n",
    "\n",
    "# Calcular el total de registros por océano\n",
    "total_by_ocean = df_mp.groupby('Oceans').size()\n",
    "\n",
    "# Calcular el porcentaje de la región más frecuente dentro de cada océano\n",
    "percentage_most_frequent = (most_frequent_count / total_by_ocean) * 100\n",
    "\n",
    "# Crear un DataFrame con la región más frecuente y su porcentaje\n",
    "result = pd.DataFrame({\n",
    "    'Most Frequent Region': most_frequent_region,\n",
    "    'Frequency': most_frequent_count,\n",
    "    'Percentage': percentage_most_frequent\n",
    "})\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar csv filtrado\n",
    "\n",
    "# df_mp.to_csv('../../Archivos/Marine_Microplastics_POWERBI.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
